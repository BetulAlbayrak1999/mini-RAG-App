{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUtogD1LCEmO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "print(\"CUDA Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuxFqYN-FEYX"
      },
      "outputs": [],
      "source": [
        "##for updating lshw\n",
        "!sudo apt update && sudo apt install -y pciutils lshw\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezm5s0Mx3ShW"
      },
      "outputs": [],
      "source": [
        "# use this command to kill all ollama\n",
        "!pkill -f ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0c0MYJkkzBBz"
      },
      "outputs": [],
      "source": [
        "##download ollama\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CnVQoFVy21n7"
      },
      "outputs": [],
      "source": [
        "ollama_model_id= \"gemma2:2b-instruct-fp16\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ANsJyKf3UxJ"
      },
      "outputs": [],
      "source": [
        "!nohup bash -c \"OLLAMA_HOST=0.0.0.0:8080 OLLAMA_ORIGIN=* ollama serve\" &\n",
        "!sleep 5 && tail /content/nohup.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fL_vOaoCHksO"
      },
      "outputs": [],
      "source": [
        "!curl http://127.0.0.1:8080/api/tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmneaSy44B5B"
      },
      "outputs": [],
      "source": [
        "! ollama pull {ollama_model_id}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfpb3YIk5eZ4"
      },
      "outputs": [],
      "source": [
        "!nohup bash -c \"OLLAMA_HOST=0.0.0.0:8080 OLLAMA_ORIGIN=* ollama run {ollama_model_id}\" &\n",
        "!sleep 5 && tail /content/nohup.out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyDJvXdQ5002"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "curl http://localhost:8080/api/chat -d '{\n",
        "  \"model\": \"gemma2:2b-instruct-fp16\",\n",
        "  \"messages\": [\n",
        "    { \"role\": \"user\", \"content\": \"ما لون الشمس الحقيقي\" }\n",
        "  ]\n",
        "}'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bn4QIfY06Mx_"
      },
      "source": [
        "## **Ngrok**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taoKeQss6LUl"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "ngrok_auth= userdata.get(\"colab-ngrok\")\n",
        "conf.get_default().auth_token= ngrok_auth\n",
        "port= \"8000\"\n",
        "\n",
        "public_url= ngrok.connect(port).public_url\n",
        "print(public_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gCOMOyXOC8wX"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "curl NGROK API KEY HERE/api/chat -d '{\n",
        "  \"model\": \"gemma2:2b-instruct-fp16\",\n",
        "  \"messages\": [\n",
        "    { \"role\": \"user\", \"content\": \"ما لون الشمس الحقيقي\" }\n",
        "  ]\n",
        "}'"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
